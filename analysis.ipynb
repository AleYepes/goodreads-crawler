{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ollama\n",
    "from tqdm import tqdm \n",
    "\n",
    "# Load Data\n",
    "goodreads_df = pd.read_csv('data/goodreads_library_export.csv')\n",
    "book_df = pd.read_csv(\"data/books.csv\")\n",
    "book_df['year'] = book_df['year'].astype('Int32')\n",
    "OLLAMA_MODEL = \"qwen3-embedding:0.6b\"\n",
    "\n",
    "book_df['book_id'] = book_df['book_id'].astype(str)\n",
    "goodreads_df['book_id'] = goodreads_df['book_id'].astype(str)\n",
    "book_df = book_df.merge(goodreads_df[['book_id', 'my_rating']], on='book_id', how='left')\n",
    "\n",
    "# Sentence embeddings\n",
    "all_genres = book_df['genres'].str.split('|').explode().str.strip().unique()\n",
    "all_genres = [g for g in all_genres if isinstance(g, str) and len(g) > 0]\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "genre_embeddings = {}\n",
    "for i in tqdm(range(0, len(all_genres), BATCH_SIZE)):\n",
    "    batch = all_genres[i : i + BATCH_SIZE]\n",
    "    response = ollama.embed(model=OLLAMA_MODEL, input=batch)\n",
    "    for genre, vector in zip(batch, response['embeddings']):\n",
    "        genre_embeddings[genre] = np.array(vector)\n",
    "\n",
    "genre_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from node2vec import Node2Vec\n",
    "from sklearn.preprocessing import normalize, StandardScaler\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, WhiteKernel\n",
    "import networkx as nx\n",
    "import umap\n",
    "\n",
    "\n",
    "# 2. Graph Embeddings (Structure)\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(book_df['book_id'].tolist())\n",
    "\n",
    "# Edge Type A: \"Similar Books\" (from Goodreads)\n",
    "for idx, row in book_df.iterrows():\n",
    "    if pd.isna(row['similar_books']): continue\n",
    "    for item in row['similar_books'].split('|'):\n",
    "        try:\n",
    "            target_id = item.split(':')[0]\n",
    "            if target_id in book_df['book_id'].values:\n",
    "                G.add_edge(row['book_id'], target_id, weight=1.0)\n",
    "        except ValueError: continue\n",
    "\n",
    "# # Edge Type B: Series (Strong connection)\n",
    "# # Connecting books in the same series strengthens the graph significantly\n",
    "# series_groups = book_df[book_df['series'].notna()].groupby('series')['book_id'].apply(list)\n",
    "# for books in series_groups:\n",
    "#     for i in range(len(books)-1):\n",
    "#         G.add_edge(books[i], books[i+1], weight=10.0) # High weight for series\n",
    "\n",
    "node2vec = Node2Vec(G, dimensions=64, walk_length=10, num_walks=50, workers=4, quiet=True)\n",
    "model_n2v = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "\n",
    "graph_embeddings = np.array([\n",
    "    model_n2v.wv[bid] if bid in model_n2v.wv else np.zeros(64) \n",
    "    for bid in book_df['book_id']\n",
    "])\n",
    "\n",
    "# 3. Concatenate\n",
    "final_embeddings = np.hstack([\n",
    "    normalize(content_embeddings, norm='l2'), \n",
    "    normalize(graph_embeddings, norm='l2')\n",
    "])\n",
    "\n",
    "# PART B: The Global Score (Pop-Rank)\n",
    "\n",
    "C = book_df['avg_rating'].mean()\n",
    "m = book_df['review_count'].quantile(0.10) # 10th percentile as minimum votes\n",
    "\n",
    "def weighted_rating(x, m=m, C=C):\n",
    "    v = x['review_count']\n",
    "    R = x['avg_rating']\n",
    "    if v == 0: return C\n",
    "    return (v/(v+m) * R) + (m/(v+m) * C)\n",
    "\n",
    "book_df['global_score'] = book_df.apply(weighted_rating, axis=1)\n",
    "\n",
    "# PART C: The Personal Score (UMAP + GPR)\n",
    "\n",
    "# 1. Semi-Supervised UMAP\n",
    "# We need a target array. -1 signals \"unlabeled\" to UMAP.\n",
    "# This warps the space so your rated books clump together based on score.\n",
    "y_umap = book_df['my_rating'].fillna(-1).values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(final_embeddings)\n",
    "\n",
    "reducer = umap.UMAP(\n",
    "    n_neighbors=15,\n",
    "    n_components=10,    # Reduce to 10 dims for the regressor\n",
    "    metric='cosine', \n",
    "    target_metric='l1', # Use L1 for the ratings\n",
    "    target_weight=0.5,  # Balance structural shape vs rating shape\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Running UMAP...\")\n",
    "X_reduced = reducer.fit_transform(X_scaled, y=y_umap)\n",
    "\n",
    "# 2. Gaussian Process Regression\n",
    "# Identify Training set (Books you read) vs Prediction set (Unread)\n",
    "train_mask = book_df['my_rating'].notna() & (book_df['my_rating'] > 0)\n",
    "X_train = X_reduced[train_mask]\n",
    "y_train = book_df.loc[train_mask, 'my_rating'].values\n",
    "\n",
    "# Kernel: Matern handles irregularities better than RBF. WhiteKernel handles noise.\n",
    "kernel = Matern(nu=1.5) + WhiteKernel(noise_level=0.1)\n",
    "gpr = GaussianProcessRegressor(kernel=kernel, normalize_y=True)\n",
    "\n",
    "print(\"Fitting GPR...\")\n",
    "gpr.fit(X_train, y_train)\n",
    "\n",
    "# Predict on ALL books\n",
    "means, stds = gpr.predict(X_reduced, return_std=True)\n",
    "\n",
    "book_df['pred_rating'] = means\n",
    "book_df['uncertainty'] = stds\n",
    "\n",
    "# PART D: Final Hybrid Scoring\n",
    "\n",
    "# Conservative Personal Score: Prediction minus Uncertainty\n",
    "# If model thinks it's 5.0 but is unsure (std=1.0), treats it as 4.0\n",
    "book_df['safe_personal_score'] = book_df['pred_rating'] - (book_df['uncertainty'] * 0.5)\n",
    "\n",
    "# Hybrid: 70% Personal Taste, 30% Global Quality\n",
    "book_df['final_score'] = (0.7 * book_df['safe_personal_score']) + (0.3 * book_df['global_score'])\n",
    "\n",
    "# Filter out books you've already read\n",
    "recs = book_df[~train_mask].sort_values('final_score', ascending=False)\n",
    "\n",
    "# Export\n",
    "recs[['title', 'authors', 'global_score', 'pred_rating', 'uncertainty', 'final_score']].head(20).to_csv(\"data/final_recommendations.csv\", index=False)\n",
    "print(\"Done. Saved top 20 to data/final_recommendations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_recommendations(title, embeddings, df, top_k=5):\n",
    "    idx = df[df['title'] == title].index[0]\n",
    "    sim_scores = cosine_similarity([embeddings[idx]], embeddings).flatten()\n",
    "    top_indices = sim_scores.argsort()[-(top_k+1):-1][::-1]\n",
    "    \n",
    "    return df.iloc[top_indices][['title', 'authors', 'genres']]\n",
    "\n",
    "# Test it out\n",
    "# print(get_recommendations(\"The Way of Kings\", final_embeddings, df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodreads_df = pd.read_csv('data/goodreads_library_export.csv')\n",
    "goodreads_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodreads_export = pd.read_csv(new_export_path)\n",
    "# goodreads_export = pd.read_csv('data/20-01-2025_goodreads_library_export.csv')\n",
    "goodreads_export['Original Publication Year'] = goodreads_export['Original Publication Year'].fillna(goodreads_export['Year Published'])\n",
    "goodreads_export = goodreads_export[['Book Id', 'Author', 'My Rating', 'Number of Pages', 'Original Publication Year']]\n",
    "goodreads_export = goodreads_export.rename(columns={'Book Id':'book_id',\n",
    "                                                    'Author': 'author',\n",
    "                                                    'My Rating': 'my_rating',\n",
    "                                                    'Number of Pages': 'num_pages',\n",
    "                                                    'Original Publication Year': 'year'})\n",
    "threshold = (goodreads_export['num_pages'].mean() - goodreads_export['num_pages'].std())\n",
    "goodreads_export.loc[goodreads_export['num_pages'] < threshold, 'num_pages'] = np.nan\n",
    "\n",
    "book_df = pd.read_csv(this_months_scrape_path)\n",
    "# book_df = pd.read_csv('data/01-2025_goodreads_scraped.csv')\n",
    "df = goodreads_export.merge(book_df, on='book_id')\n",
    "\n",
    "# Drop competing columns\n",
    "df['author'] = df['author_x'].fillna(df['author_y'])\n",
    "df['num_pages'] = df['num_pages_x'].fillna(df['num_pages_y'])\n",
    "df['year'] = df['year_x'].fillna(df['year_y'])\n",
    "df.drop(columns=['author_x', 'author_y', 'num_pages_x', 'num_pages_y', 'year_x', 'year_y'], inplace=True)\n",
    "\n",
    "df['genres'] = df['genres'].apply(lambda x: ast.literal_eval(x) if pd.notna(x) else [])\n",
    "df['year'] = df['year'].fillna(df['year'].mean()).round().astype(int)\n",
    "df['num_pages'] = df['num_pages'].fillna(df['num_pages'].mean()).round().astype(int)\n",
    "df['num_reviews'] = df['num_reviews'].fillna(0).round().astype(int)\n",
    "df['my_rating'] = df['my_rating'].replace(0,np.nan)\n",
    "\n",
    "df['age'] = int(datetime.now().strftime('%Y')) - df['year']\n",
    "df['average_rating'] = ((df['5 stars'] * 5) + (df['4 stars'] * 4) + (df['3 stars'] * 3) + (df['2 stars'] * 2) + df['1 star']) / df['num_ratings']\n",
    "df = df[['book_id', 'title', 'author', 'year', 'age', 'series', 'num_pages', 'genres', 'num_ratings', 'num_reviews', 'my_rating', 'average_rating', '5 stars', '4 stars', '3 stars', '2 stars', '1 star']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_quadratic(row):\n",
    "    x = np.array([1, 2, 3, 4, 5])\n",
    "    a, b, c = np.polyfit(x, row, 2)\n",
    "    return pd.Series([a, b, c])\n",
    "\n",
    "# Calculating quadrdic modeling coefficients\n",
    "df['1_star_percentage'] = df['1 star'] / df['num_ratings']\n",
    "df['2_star_percentage'] = df['2 stars'] / df['num_ratings']\n",
    "df['3_star_percentage'] = df['3 stars'] / df['num_ratings']\n",
    "df['4_star_percentage'] = df['4 stars'] / df['num_ratings']\n",
    "df['5_star_percentage'] = df['5 stars'] / df['num_ratings']\n",
    "coefficients = df[['1_star_percentage','2_star_percentage','3_star_percentage','4_star_percentage','5_star_percentage']].apply(fit_quadratic, axis=1)\n",
    "df['a'], df['b'], df['c'] = coefficients[0], coefficients[1], coefficients[2]\n",
    "\n",
    "# Pre-processing columns for rankings\n",
    "df['num_ratings_ln'] = np.log1p(df['num_ratings'])\n",
    "df['num_pages_ln'] = np.log1p(df['num_pages'])\n",
    "df['2a_shifted'] = df['a'] - df['a'].min()\n",
    "df['2a_shifted'] = df['2a_shifted'] * (1 / df['2a_shifted'].max()) + 1\n",
    "df['b_shifted'] = df['b'] - df['b'].min()\n",
    "df['b_shifted'] = df['b_shifted'] * (1 / df['b_shifted'].max()) + 1\n",
    "df['c_shifted'] = df['c'] - df['c'].min()\n",
    "df['c_shifted'] = df['c_shifted'] * (1 / df['c_shifted'].max()) + 1\n",
    "\n",
    "# Types of rankings\n",
    "df['num_adjusted_rating'] = df['average_rating'] - (df['average_rating'] - df['average_rating'].mean()) / df['num_ratings_ln']\n",
    "df['coeff_2a_rating'] = (df['num_adjusted_rating'] * df['2a_shifted'])\n",
    "df['coeff_b_rating'] = (df['num_adjusted_rating']) / (df['b_shifted'])\n",
    "df['coeff_c_rating'] = (df['num_adjusted_rating'] * df['c_shifted'])\n",
    "df['joined_rating'] = (df['num_adjusted_rating'] * df['c_shifted'] * df['2a_shifted']) / df['b_shifted']\n",
    "df['final_rating'] = df['joined_rating'] - (df['joined_rating'] - df['joined_rating'].mean()) / df['num_ratings_ln']\n",
    "\n",
    "df['num_adjusted_page_rating'] = df['num_adjusted_rating'] / (df['num_pages_ln'])\n",
    "df['coeff_2a_page_rating'] = df['coeff_2a_rating'] / df['num_pages_ln']\n",
    "df['coeff_b_page_rating'] = df['coeff_b_rating'] / df['num_pages_ln']\n",
    "df['coeff_c_page_rating'] = df['coeff_c_rating'] / df['num_pages_ln']\n",
    "df['joined_page_rating'] = df['joined_rating'] / df['num_pages_ln']\n",
    "df['final_page_rating'] = df['joined_page_rating'] - (df['joined_page_rating'] - df['joined_page_rating'].mean()) / df['num_ratings_ln']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = ['age', 'num_pages', 'num_pages_ln', 'num_ratings', 'num_ratings_ln', 'num_reviews', 'my_rating', 'average_rating', '1 star', '2 stars', '3 stars', '4 stars', '5 stars', '1_star_percentage', '2_star_percentage', '3_star_percentage', '4_star_percentage', '5_star_percentage', 'a', 'b', 'c', 'num_adjusted_rating', 'coeff_2a_rating', 'coeff_b_rating', 'coeff_c_rating', 'joined_rating', 'final_rating', 'num_adjusted_page_rating', 'coeff_2a_page_rating', 'coeff_b_page_rating', 'coeff_c_page_rating', 'joined_page_rating', 'final_page_rating']\n",
    "corr_df= df[numeric_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(20, 15)) \n",
    "sns.heatmap(corr_df, annot=True, cmap='coolwarm', linewidths=0.5) \n",
    "plt.title('Correlation Heatmap') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fresh = df.sort_values(by='final_page_rating', ascending=False).reset_index().drop('index', axis=1)\n",
    "fresh = fresh[fresh['my_rating'].isna()]\n",
    "fresh[['Fiction' in genre_list for genre_list in fresh['genres']]] # Fiction, Nonfiction, Memoir, Classics, History, Politics, Philosophy, Business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('books_data.csv')\n",
    "test#['author'].iloc[]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
