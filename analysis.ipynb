{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prep data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "books_df = pd.read_csv(\"data/books.csv\")\n",
    "star_cols = [c for c in books_df.columns if c.endswith('star')]\n",
    "books_df['rating_count'] = books_df[star_cols].sum(axis=1)\n",
    "\n",
    "books_df['lang'] = [\n",
    "    \"|\".join(item.strip() for item in x.split(\";\")) if isinstance(x, str) else x \n",
    "    for x in books_df['lang']\n",
    "]\n",
    "books_df['description'] = books_df['description'].str.replace('\\n\\n', '\\n')\n",
    "books_df['description'] = books_df['description'].str.replace('\\n', ' ')\n",
    "books_df['description'] = books_df['description'].str.replace('   ', ' ')\n",
    "books_df['description'] = books_df['description'].str.replace('  ', ' ')\n",
    "\n",
    "# Elaborate my ratings with pair comparisons\n",
    "class BookRanker:\n",
    "    def __init__(self, df, rating_col='my_rating', title_col='title', id_col='book_id'):\n",
    "        self.df = df.copy()\n",
    "        self.rating_col = rating_col\n",
    "        self.title_col = title_col\n",
    "        self.id_col = id_col\n",
    "        \n",
    "        if 'elo_score' not in self.df.columns:\n",
    "            self.df['elo_score'] = 1200.0\n",
    "        if 'matches_played' not in self.df.columns:\n",
    "            self.df['matches_played'] = 0\n",
    "\n",
    "    def get_expected_score(self, ra, rb):\n",
    "        return 1 / (1 + 10 ** ((rb - ra) / 400))\n",
    "\n",
    "    def update_elo(self, ra, rb, result, k=32):\n",
    "        expected_a = self.get_expected_score(ra, rb)\n",
    "        new_ra = ra + k * (result - expected_a)\n",
    "        new_rb = rb + k * ((1 - result) - (1 - expected_a))\n",
    "        return new_ra, new_rb\n",
    "\n",
    "    def rank_bucket(self, star_rating):\n",
    "        bucket_indices = self.df[self.df[self.rating_col] == star_rating].index.tolist()\n",
    "        \n",
    "        if len(bucket_indices) < 2:\n",
    "            print(f\"Not enough books with {star_rating} stars to compare.\")\n",
    "            return\n",
    "\n",
    "        print(f\"\\n--- Ranking {star_rating}-Star Books ---\")\n",
    "        print(f\"Pick the winner\")\n",
    "        counter = 0\n",
    "        while True:\n",
    "            weights = 1 / (self.df.loc[bucket_indices, 'matches_played'] + 1)\n",
    "            idx_a, idx_b = random.choices(bucket_indices, weights=weights, k=2)\n",
    "            if idx_a == idx_b:\n",
    "                continue\n",
    "\n",
    "            book_a = self.df.loc[idx_a]\n",
    "            book_b = self.df.loc[idx_b]\n",
    "\n",
    "            choice = input(f\"[1]{book_a[self.title_col]}\\nvs\\n[2]{book_b[self.title_col]}\").strip().lower()\n",
    "\n",
    "            if choice == 'q':\n",
    "                break\n",
    "            elif choice == '3':\n",
    "                continue\n",
    "            elif choice in ['1', '2']:\n",
    "                # Update match counts\n",
    "                self.df.loc[idx_a, 'matches_played'] += 1\n",
    "                self.df.loc[idx_b, 'matches_played'] += 1\n",
    "\n",
    "                # Calculate new Elo\n",
    "                ra = book_a['elo_score']\n",
    "                rb = book_b['elo_score']\n",
    "                \n",
    "                # If choice is 1, A wins (result=1). If 2, B wins (result=0).\n",
    "                result = 1 if choice == '1' else 0\n",
    "                new_ra, new_rb = self.update_elo(ra, rb, result)\n",
    "                \n",
    "                self.df.loc[idx_a, 'elo_score'] = new_ra\n",
    "                self.df.loc[idx_b, 'elo_score'] = new_rb\n",
    "\n",
    "                counter += 1\n",
    "                if counter % 10 == 0:\n",
    "                    print(f'{counter} done')\n",
    "            else:\n",
    "                print(\"Invalid input.\")\n",
    "\n",
    "    def calculate_continuous_score(self):\n",
    "        \"\"\"\n",
    "        Maps Elo scores to a continuous 1-5 scale.\n",
    "        Example: A 4-star book with high Elo becomes 4.9, low Elo becomes 4.0.\n",
    "        \"\"\"\n",
    "        self.df['continuous_rating'] = np.nan\n",
    "\n",
    "        for stars in sorted(self.df[self.rating_col].dropna().unique()):\n",
    "            subset_mask = self.df[self.rating_col] == stars\n",
    "            subset = self.df[subset_mask]\n",
    "            \n",
    "            if len(subset) == 0: continue\n",
    "            if len(subset) == 1:\n",
    "                self.df.loc[subset_mask, 'continuous_rating'] = stars + 0.5\n",
    "                continue\n",
    "\n",
    "            # Min-Max Normalization\n",
    "            min_elo = subset['elo_score'].min()\n",
    "            max_elo = subset['elo_score'].max()\n",
    "            \n",
    "            # Avoid division by zero if all elos are identical\n",
    "            if max_elo == min_elo:\n",
    "                normalized = 0.5\n",
    "            else:\n",
    "                normalized = (subset['elo_score'] - min_elo) / (max_elo - min_elo)\n",
    "            \n",
    "            # Map 0.0-1.0 range to (Stars)-(Stars+1)\n",
    "            # Example: 4 stars -> maps to 4.00 to 4.99\n",
    "            # You can adjust scaling factor (e.g., * 0.9 + 0.05) if you don't want hard 4.0 or 5.0\n",
    "            self.df.loc[subset_mask, 'continuous_rating'] = stars + (normalized * 0.99)\n",
    "\n",
    "        return self.df\n",
    "\n",
    "goodreads_df = pd.read_csv('data/goodreads_library_export.csv')\n",
    "goodreads_df['my_rating'] = goodreads_df['my_rating'].astype('UInt8').replace(0, np.nan)\n",
    "\n",
    "if os.path.exists('data/elo_ratings.csv'):\n",
    "    saved_df = pd.read_csv('data/elo_ratings.csv')\n",
    "    ranker = BookRanker(saved_df, rating_col='my_rating', title_col='title', id_col='book_id')\n",
    "else:\n",
    "    ranker = BookRanker(goodreads_df, rating_col='my_rating', title_col='title', id_col='book_id')\n",
    "\n",
    "if input(\"rank? (y/n)\").lower() == 'y':\n",
    "    ranker.rank_bucket(5) \n",
    "    ranker.rank_bucket(4) \n",
    "    ranker.rank_bucket(3) \n",
    "    ranker.rank_bucket(2) \n",
    "    ranker.rank_bucket(1) \n",
    "    ranker.df.to_csv('data/elo_ratings.csv', index=False)\n",
    "\n",
    "ranked_df = ranker.calculate_continuous_score()[['book_id', 'continuous_rating']]\n",
    "books_df = books_df.merge(ranked_df, on='book_id', how='left')\n",
    "books_df = books_df.rename(columns={'continuous_rating': 'my_rating'})\n",
    "\n",
    "# Include my friend's ratings\n",
    "friends_df = pd.read_csv(\"data/friend_ratings.csv\")\n",
    "friends_df['rating'] = friends_df['rating'].astype('UInt8').replace(0, np.nan)\n",
    "friends_df = friends_df[~friends_df['rating'].isna()]\n",
    "\n",
    "comparison_df = friends_df.merge(books_df[['book_id', 'my_rating']], on='book_id', how='inner')\n",
    "comparison_df = comparison_df.groupby('list_id').agg(correlation=('rating', lambda x: x.corr(comparison_df.loc[x.index, 'my_rating'], method='spearman')))\n",
    "\n",
    "similar_readers = comparison_df[(comparison_df['correlation'] > 0)].index\n",
    "\n",
    "friends_df = friends_df[friends_df['list_id'].isin(similar_readers)]\n",
    "predicted_ratings = friends_df.groupby('book_id')['rating'].mean()\n",
    "\n",
    "books_df['training_ratings'] = books_df['my_rating']\n",
    "books_df['training_ratings'] = books_df['training_ratings'].fillna(books_df['book_id'].map(predicted_ratings))\n",
    "books_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep embedding strings\n",
    "def format_string_for_embedding(items, kind=None, truncate=0):\n",
    "    if not isinstance(items, (list)) or len(items) == 0:\n",
    "        return \"\"\n",
    "\n",
    "    n = len(items)\n",
    "    if n == 1:\n",
    "        res = items[0]\n",
    "    elif n > truncate > 1:\n",
    "        res = f\"{', '.join(items[:truncate])}, and {items[truncate]}\"\n",
    "    else:\n",
    "        res = f\"{', '.join(items[:-1])}{',' if n > 2 else ''} and {items[-1]}\"\n",
    "    \n",
    "    prefix = f\"{kind.capitalize()}{'s' if n > 1 else ''}: \" if kind else \"\"\n",
    "    return f\"{prefix}{res}\"\n",
    "\n",
    "books_df['authors_post'] = books_df['authors'].str.split('|')\n",
    "books_df['authors_post'] = books_df['authors_post'].apply(lambda x:format_string_for_embedding(x, truncate=4))\n",
    "\n",
    "books_df['genres_post'] = books_df['genres'].str.split('|')\n",
    "books_df['genres_post'] = books_df['genres_post'].apply(lambda x:format_string_for_embedding(x, kind='genre'))\n",
    "\n",
    "books_df['desc_post'] = [[desc] if isinstance(desc, str) else [] for desc in books_df['description']]\n",
    "books_df['desc_post'] = books_df['desc_post'].apply(lambda x:format_string_for_embedding(x, kind='description'))\n",
    "\n",
    "def join_embedding_parts(title, authors, genres, desc):\n",
    "    text = f\"Book: {title}\\n\"\n",
    "    if authors:\n",
    "        text += f\"Written by: {authors}\\n\"\n",
    "    if genres:\n",
    "        text += f\"{genres}\\n\"\n",
    "    if desc:\n",
    "        text += f\"{desc}\" \n",
    "    return text\n",
    "\n",
    "books_df['embedding_input'] = [\n",
    "    join_embedding_parts(t, a, g, d) \n",
    "    for t, a, g, d in zip(books_df['title'], books_df['authors_post'], books_df['genres_post'], books_df['desc_post'])\n",
    "]\n",
    "id_to_string = books_df.set_index('book_id')['embedding_input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed sentences\n",
    "import os\n",
    "import ollama\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "PARAMS = 8\n",
    "OLLAMA_MODEL = f\"qwen3-embedding:{PARAMS}b\"\n",
    "MIN_DIMENSIONS = 32\n",
    "\n",
    "train_size = (~books_df['training_ratings'].isna()).sum()\n",
    "mrl_dimensions = MIN_DIMENSIONS\n",
    "while mrl_dimensions*2 < train_size:\n",
    "    mrl_dimensions*=2\n",
    "\n",
    "embeddings_path = f'data/{PARAMS}b_embeddings.csv'\n",
    "if os.path.exists(embeddings_path):\n",
    "    embeddings = pd.read_csv(embeddings_path).set_index('book_id')\n",
    "    embeddings.columns = embeddings.columns.astype(int)\n",
    "    embeddings = pd.DataFrame(embeddings).dropna(subset=[0])\n",
    "else:\n",
    "    embeddings = pd.DataFrame()\n",
    "\n",
    "current_ids = books_df['book_id'].values\n",
    "missing_ids = [idx for idx in current_ids if idx not in embeddings.index]\n",
    "if missing_ids:\n",
    "    missing_strings = id_to_string.loc[missing_ids].tolist()\n",
    "    batch_size = 128\n",
    "    new_embeddings = []\n",
    "    for i in tqdm(range(0, len(missing_strings), batch_size)):\n",
    "        batch = missing_strings[i : i + batch_size]\n",
    "        response = ollama.embed(model=OLLAMA_MODEL, input=batch)\n",
    "        new_embeddings.extend(response['embeddings'])\n",
    "\n",
    "    new_embeddings = pd.DataFrame(new_embeddings, index=missing_ids)\n",
    "    new_embeddings.index.name = 'book_id'\n",
    "    embeddings = pd.concat([embeddings, new_embeddings])\n",
    "    embeddings.to_csv(embeddings_path)\n",
    "    del new_embeddings, missing_strings, missing_ids, current_ids\n",
    "\n",
    "embeddings = embeddings.loc[books_df['book_id']].values\n",
    "embeddings = embeddings[:, :mrl_dimensions*2] # qwen-3 embedding supports MRL\n",
    "norm = Normalizer(norm='l2')\n",
    "embeddings = norm.fit_transform(embeddings)\n",
    "embeddings = torch.tensor(embeddings, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build adjacency matrix\n",
    "from torch_geometric.utils import add_self_loops\n",
    "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
    "\n",
    "id_to_idx = {id: i for i, id in enumerate(books_df['book_id'])}\n",
    "\n",
    "edge_indices = []\n",
    "for idx, row in tqdm(books_df.iterrows(), total=len(books_df)):\n",
    "    current_idx = id_to_idx[row['book_id']]\n",
    "    if pd.isna(row['similar_books']):\n",
    "        continue\n",
    "    for item in row['similar_books'].split('|'):\n",
    "        try:\n",
    "            target_id = int(item.split(':')[0])\n",
    "            if target_id in books_df['book_id'].values:\n",
    "                target_idx = id_to_idx[target_id]\n",
    "                edge_indices.append([current_idx, target_idx])\n",
    "                edge_indices.append([target_idx, current_idx])\n",
    "        except (ValueError, IndexError):\n",
    "            continue\n",
    "\n",
    "if not edge_indices:\n",
    "    edge_index = torch.tensor([[], []], dtype=torch.long)\n",
    "else:\n",
    "    edge_index = torch.tensor(edge_indices, dtype=torch.long).t().contiguous()\n",
    "\n",
    "edge_index_with_loops, _ = add_self_loops(edge_index, num_nodes=embeddings.size(0))\n",
    "edge_index_norm, edge_weight_norm = gcn_norm(edge_index_with_loops, num_nodes=embeddings.size(0))\n",
    "adj_matrix = torch.sparse_coo_tensor(edge_index_norm, edge_weight_norm, (embeddings.size(0), embeddings.size(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nevergrad as ng\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import ndcg_score, mean_squared_error\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "def objective(num_propagations, \n",
    "              knn_neighbors,\n",
    "              brr_alpha_1, brr_alpha_2, brr_lambda_1, brr_lambda_2, brr_uncertainty_penalty,\n",
    "              svr_C, svr_epsilon,\n",
    "              knn_weight, brr_weight\n",
    "              ):\n",
    "    \n",
    "    all_embeddings = precomputed_embeddings[num_propagations]\n",
    "    X = all_embeddings[training_mask]\n",
    "    y = my_ratings\n",
    "\n",
    "    y_trues = []\n",
    "    y_preds = []\n",
    "    skf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    for train_idx, test_idx in skf.split(X):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        knn = KNeighborsRegressor(\n",
    "            n_neighbors=knn_neighbors,\n",
    "            metric='cosine', \n",
    "            weights='distance',\n",
    "            n_jobs=-1,\n",
    "            )\n",
    "        knn.fit(X_train, y_train)\n",
    "        knn_pred = knn.predict(X_test)\n",
    "\n",
    "        brr = BayesianRidge(\n",
    "            alpha_1=brr_alpha_1,\n",
    "            alpha_2=brr_alpha_2,\n",
    "            lambda_1=brr_lambda_1,\n",
    "            lambda_2=brr_lambda_2,\n",
    "            compute_score=True\n",
    "            )\n",
    "        brr.fit(X_train, y_train)\n",
    "        brr_mu, brr_std = brr.predict(X_test, return_std=True)\n",
    "        brr_pred = brr_mu - (brr_uncertainty_penalty * brr_std)\n",
    "\n",
    "        svr = SVR(\n",
    "            kernel='rbf',\n",
    "            gamma='scale',\n",
    "            C=svr_C, \n",
    "            epsilon=svr_epsilon\n",
    "            ) \n",
    "        svr.fit(X_train, y_train)\n",
    "        svr_pred = svr.predict(X_test)\n",
    "\n",
    "        remaining_weight = 1 - knn_weight\n",
    "        brr_weight *= remaining_weight\n",
    "        svr_weight = remaining_weight - brr_weight\n",
    "        final_pred = (knn_weight * knn_pred) + (brr_weight * brr_pred) + (svr_weight * svr_pred)\n",
    "\n",
    "        y_trues.append(y_test)\n",
    "        y_preds.append(final_pred)\n",
    "\n",
    "    y_trues = np.concatenate(y_trues)\n",
    "    y_preds = np.concatenate(y_preds)\n",
    "    \n",
    "    # mse = mean_squared_error(y_trues, y_preds)\n",
    "    ndcg = ndcg_score([y_trues], [y_preds])\n",
    "    if np.std(y_preds) < 1e-9:\n",
    "        spearman = 0.0\n",
    "    else:\n",
    "        spearman, _ = spearmanr(y_trues, y_preds)\n",
    "        if np.isnan(spearman): spearman = 0.0\n",
    "\n",
    "    # return mse + (1.0 - ndcg) + (1.0 - spearman)\n",
    "    return ndcg - spearman\n",
    "\n",
    "MAX_PROPAGATIONS = 2\n",
    "propagated = embeddings.clone()\n",
    "norm_l2 = Normalizer(norm='l2')\n",
    "precomputed_embeddings = [norm_l2.transform(propagated.numpy())]\n",
    "\n",
    "for _ in range(MAX_PROPAGATIONS):\n",
    "    propagated = torch.sparse.mm(adj_matrix, propagated)\n",
    "    precomputed_embeddings.append(norm_l2.transform(propagated.numpy()))\n",
    "del propagated\n",
    "\n",
    "training_mask = ~books_df['training_ratings'].isna()\n",
    "my_ratings = books_df.loc[training_mask, 'training_ratings'].values\n",
    "\n",
    "parametrization = ng.p.Instrumentation(\n",
    "    num_propagations = ng.p.Scalar(lower=0, upper=MAX_PROPAGATIONS).set_integer_casting(),\n",
    "\n",
    "    knn_neighbors = ng.p.Scalar(lower=3, upper=mrl_dimensions//2).set_integer_casting(),\n",
    "    brr_alpha_1=ng.p.Scalar(lower=1e-7, upper=1e-3),\n",
    "    brr_alpha_2=ng.p.Scalar(lower=1e-7, upper=1e-3),\n",
    "    brr_lambda_1=ng.p.Log(lower=1e-6, upper=1e-1),\n",
    "    brr_lambda_2=ng.p.Log(lower=1e-6, upper=1e-1),\n",
    "    brr_uncertainty_penalty=ng.p.Scalar(lower=0, upper=2.0),\n",
    "    svr_C = ng.p.Log(lower=1e-3, upper=1e2),\n",
    "    svr_epsilon = ng.p.Scalar(lower=0.0, upper=1.0),\n",
    "\n",
    "    knn_weight=ng.p.Scalar(lower=0, upper=1), \n",
    "    brr_weight=ng.p.Scalar(lower=0, upper=1), \n",
    ")\n",
    "\n",
    "BUDGET = 300\n",
    "optimizer = ng.optimizers.NGOpt(parametrization=parametrization, budget=BUDGET)\n",
    "best_loss = float('inf')\n",
    "with tqdm(total=BUDGET) as pbar:\n",
    "    for i in range(BUDGET):\n",
    "        x = optimizer.ask()\n",
    "        loss = objective(*x.args, **x.kwargs)\n",
    "        optimizer.tell(x, loss)\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "        pbar.update(1)\n",
    "        if i % 10 == 0:\n",
    "            pbar.set_description(f\"Best Loss: {best_loss:.4f}\")\n",
    "\n",
    "best_params = optimizer.provide_recommendation().kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"8 MRL sliced\n",
    "Best Loss: 1.5714: 100%|██████████| 300/300 [11:49<00:00,  2.37s/it]\n",
    "{'num_propagations': 0,\n",
    " 'knn_neighbors': 17,\n",
    " 'brr_alpha_1': 0.0006421576956932416,\n",
    " 'brr_alpha_2': 0.0004509358497670652,\n",
    " 'brr_lambda_1': 8.24637589893822e-06,\n",
    " 'brr_lambda_2': 0.0001968595842801841,\n",
    " 'brr_uncertainty_penalty': 1.3679433872638418,\n",
    " 'svr_C': 0.004026523432673821,\n",
    " 'svr_epsilon': 0.3118081208045217,\n",
    " 'knn_weight': 0.5805897543886746,\n",
    " 'brr_weight': 0.7793002684038448}\"\"\"\n",
    "\n",
    "\"\"\"8 full\n",
    "Best Loss: 1.6065: 100%|██████████| 300/300 [16:57<00:00,  3.39s/it]\n",
    " {'num_propagations': 0,\n",
    " 'knn_neighbors': 36,\n",
    " 'brr_alpha_1': 0.0006880608281295565,\n",
    " 'brr_alpha_2': 0.0003014766980578955,\n",
    " 'brr_lambda_1': 1.3770534826263817e-05,\n",
    " 'brr_lambda_2': 0.005746291033999427,\n",
    " 'brr_uncertainty_penalty': 1.8570930538472121,\n",
    " 'svr_C': 0.03383255010384741,\n",
    " 'svr_epsilon': 0.44291277801367485,\n",
    " 'knn_weight': 0.5848794696920626,\n",
    " 'brr_weight': 0.5411997331122358}\"\"\"\n",
    "\n",
    "\"\"\"0.6 MRL sliced\n",
    "Best Loss: 1.5748: 100%|██████████| 300/300 [10:29<00:00,  2.10s/it]\n",
    "{'num_propagations': 0,\n",
    " 'knn_neighbors': 37,\n",
    " 'brr_alpha_1': 0.0002978589454364143,\n",
    " 'brr_alpha_2': 0.0005679816409316726,\n",
    " 'brr_lambda_1': 0.0003994602308099561,\n",
    " 'brr_lambda_2': 0.003659493431608586,\n",
    " 'brr_uncertainty_penalty': 1.3409360588302992,\n",
    " 'svr_C': 0.009413204523151376,\n",
    " 'svr_epsilon': 0.5861865063902226,\n",
    " 'knn_weight': 0.6849389456290866,\n",
    " 'brr_weight': 0.7766436222538672}\"\"\"\n",
    "\n",
    "\"\"\"0.6 full\n",
    "Best Loss: 1.5926: 100%|██████████| 300/300 [12:22<00:00,  2.48s/it]\n",
    "{'num_propagations': 0,\n",
    " 'knn_neighbors': 55,\n",
    " 'brr_alpha_1': 0.0007517429857762481,\n",
    " 'brr_alpha_2': 0.0003941767071639492,\n",
    " 'brr_lambda_1': 8.604754211823616e-06,\n",
    " 'brr_lambda_2': 0.008083208576838542,\n",
    " 'brr_uncertainty_penalty': 1.048016018935488,\n",
    " 'svr_C': 0.013400702917698843,\n",
    " 'svr_epsilon': 0.4149283525703265,\n",
    " 'knn_weight': 0.6826121601964188,\n",
    " 'brr_weight': 0.8414845392757134}\"\"\"\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run optimized hyperparams\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "all_embeddings = precomputed_embeddings[best_params['num_propagations']]\n",
    "\n",
    "X_train = all_embeddings[training_mask]\n",
    "y_train = my_ratings\n",
    "\n",
    "knn = KNeighborsRegressor(\n",
    "    n_neighbors=best_params['knn_neighbors'],\n",
    "    metric='cosine', \n",
    "    weights='distance',\n",
    "    n_jobs=-1,\n",
    "    )\n",
    "knn.fit(X_train, y_train)\n",
    "knn_pred = knn.predict(all_embeddings)\n",
    "\n",
    "brr = BayesianRidge(\n",
    "    alpha_1=best_params['brr_alpha_1'],\n",
    "    alpha_2=best_params['brr_alpha_2'],\n",
    "    lambda_1=best_params['brr_lambda_1'],\n",
    "    lambda_2=best_params['brr_lambda_2'],\n",
    "    compute_score=True\n",
    "    )\n",
    "brr.fit(X_train, y_train)\n",
    "brr_mu, brr_std = brr.predict(all_embeddings, return_std=True)\n",
    "brr_pred = brr_mu - (best_params['brr_uncertainty_penalty'] * brr_std)\n",
    "\n",
    "svr = SVR(\n",
    "    kernel='rbf',\n",
    "    gamma='scale',\n",
    "    C=best_params['svr_C'], \n",
    "    epsilon=best_params['svr_epsilon']\n",
    "    ) \n",
    "svr.fit(X_train, y_train)\n",
    "svr_pred = svr.predict(all_embeddings)\n",
    "\n",
    "knn_weight = best_params['knn_weight']\n",
    "brr_weight = best_params['brr_weight']\n",
    "\n",
    "remaining_weight = 1 - knn_weight\n",
    "brr_weight *= remaining_weight\n",
    "svr_weight = remaining_weight - brr_weight\n",
    "final_pred = (knn_weight * knn_pred) + (brr_weight * brr_pred) + (svr_weight * svr_pred)\n",
    "\n",
    "books_df['knn_pred'] = knn_pred\n",
    "books_df['brr_pred'] = brr_pred\n",
    "books_df['svr_pred'] = svr_pred\n",
    "books_df['final_pred'] = final_pred\n",
    "\n",
    "# cols = ['title'] + [col for col in books_df.columns if col.endswith('pred')]\n",
    "# books_df[books_df['my_rating'].isna()].sort_values(by='final_pred', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count adjusted rating\n",
    "C = books_df['avg_rating'].mean()\n",
    "m = books_df['rating_count'].quantile(0.10) \n",
    "def weighted_rating(x, m=m, C=C):\n",
    "    v = float(x['rating_count'])\n",
    "    R = float(x['avg_rating'])\n",
    "    if v == 0: \n",
    "        return C\n",
    "    return (v / (v + m) * R) + (m / (v + m) * C)\n",
    "books_df['count_adjusted_rating'] = books_df.apply(weighted_rating, axis=1)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "books_df[['count_adjusted_rating', 'final_pred']] = scaler.fit_transform(books_df[['count_adjusted_rating', 'final_pred']])\n",
    "\n",
    "# # Quadratic model coefficients\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# def fit_quadratic(row):\n",
    "#     x = np.array([1, 2, 3, 4, 5])\n",
    "#     a, b, c = np.polyfit(x, row, 2)\n",
    "#     return pd.Series([a, b, c])\n",
    "\n",
    "# books_df['1_star_percentage'] = books_df['1_star'] / books_df['rating_count']\n",
    "# books_df['2_star_percentage'] = books_df['2_star'] / books_df['rating_count']\n",
    "# books_df['3_star_percentage'] = books_df['3_star'] / books_df['rating_count']\n",
    "# books_df['4_star_percentage'] = books_df['4_star'] / books_df['rating_count']\n",
    "# books_df['5_star_percentage'] = books_df['5_star'] / books_df['rating_count']\n",
    "# coefficients = books_df[['1_star_percentage','2_star_percentage','3_star_percentage','4_star_percentage','5_star_percentage']].apply(fit_quadratic, axis=1)\n",
    "# books_df.drop(['1_star_percentage','2_star_percentage','3_star_percentage','4_star_percentage','5_star_percentage'], axis=1, inplace=True)\n",
    "\n",
    "# books_df['a'], books_df['b'], books_df['c'] = coefficients[0], coefficients[1], coefficients[2]\n",
    "# scaler = MinMaxScaler()\n",
    "# books_df[['a', 'b', 'c']] = scaler.fit_transform(books_df[['a', 'b', 'c']]) + 1\n",
    "# books_df['coeff_rating'] = books_df['a'] * books_df['c']\n",
    "# books_df['final_rating'] = books_df[['coeff_rating']] * books_df['count_adjusted_rating'] * books_df['final_pred'] / np.log1p(books_df['num_pages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df['final_rating'] = (books_df['count_adjusted_rating'] * books_df['final_pred']) #/ (np.log1p(books_df['num_pages']))\n",
    "books_df[books_df['my_rating'].isna()].sort_values(by='final_rating', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df['final_rating'] = (books_df['count_adjusted_rating'] * books_df['final_pred']) #/ (np.log1p(books_df['num_pages']))\n",
    "books_df[books_df['my_rating'].isna()].sort_values(by='final_rating', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Types of rankings\n",
    "books_df['num_adjusted_rating'] = books_df['average_rating'] - (books_df['average_rating'] - books_df['average_rating'].mean()) / books_df['num_ratings_ln']\n",
    "books_df['coeff_2a_rating'] = (books_df['num_adjusted_rating'] * books_df['2a_shifted'])\n",
    "books_df['coeff_b_rating'] = (books_df['num_adjusted_rating']) / (books_df['b_shifted'])\n",
    "books_df['coeff_c_rating'] = (books_df['num_adjusted_rating'] * books_df['c_shifted'])\n",
    "books_df['joined_rating'] = (books_df['num_adjusted_rating'] * books_df['c_shifted'] * books_df['2a_shifted']) / books_df['b_shifted']\n",
    "books_df['final_rating'] = books_df['joined_rating'] - (books_df['joined_rating'] - books_df['joined_rating'].mean()) / books_df['num_ratings_ln']\n",
    "\n",
    "books_df['num_adjusted_page_rating'] = books_df['num_adjusted_rating'] / (books_df['num_pages_ln'])\n",
    "books_df['coeff_2a_page_rating'] = books_df['coeff_2a_rating'] / books_df['num_pages_ln']\n",
    "books_df['coeff_b_page_rating'] = books_df['coeff_b_rating'] / books_df['num_pages_ln']\n",
    "books_df['coeff_c_page_rating'] = books_df['coeff_c_rating'] / books_df['num_pages_ln']\n",
    "books_df['joined_page_rating'] = books_df['joined_rating'] / books_df['num_pages_ln']\n",
    "books_df['final_page_rating'] = books_df['joined_page_rating'] - (books_df['joined_page_rating'] - books_df['joined_page_rating'].mean()) / books_df['num_ratings_ln']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodreads_export = pd.read_csv('data/goodreads_library_export.csv')\n",
    "# goodreads_export = pd.read_csv('data/20-01-2025_goodreads_library_export.csv')\n",
    "# goodreads_export = goodreads_export[['Book Id', 'Author', 'My Rating', 'Number of Pages', 'Original Publication Year']]\n",
    "# goodreads_export = goodreads_export.rename(columns={'Book Id':'book_id',\n",
    "#                                                     'Author': 'author',\n",
    "#                                                     'My Rating': 'my_rating',\n",
    "#                                                     'Number of Pages': 'num_pages',\n",
    "#                                                     'Original Publication Year': 'year'})\n",
    "threshold = (goodreads_export['number_of_pages'].mean() - goodreads_export['number_of_pages'].std())\n",
    "goodreads_export.loc[goodreads_export['number_of_pages'] < threshold, 'number_of_pages'] = np.nan\n",
    "\n",
    "book_df = pd.read_csv('data/books.csv')\n",
    "# book_df = pd.read_csv('data/01-2025_goodreads_scraped.csv')\n",
    "df = goodreads_export.merge(book_df, on='book_id')\n",
    "\n",
    "# Drop competing columns\n",
    "df['author'] = df['author_x'].fillna(df['author_y'])\n",
    "df['num_pages'] = df['num_pages_x'].fillna(df['num_pages_y'])\n",
    "df['year'] = df['year_x'].fillna(df['year_y'])\n",
    "df.drop(columns=['author_x', 'author_y', 'num_pages_x', 'num_pages_y', 'year_x', 'year_y'], inplace=True)\n",
    "\n",
    "df['genres'] = df['genres'].apply(lambda x: ast.literal_eval(x) if pd.notna(x) else [])\n",
    "df['year'] = df['year'].fillna(df['year'].mean()).round().astype(int)\n",
    "df['num_pages'] = df['num_pages'].fillna(df['num_pages'].mean()).round().astype(int)\n",
    "df['num_reviews'] = df['num_reviews'].fillna(0).round().astype(int)\n",
    "df['my_rating'] = df['my_rating'].replace(0,np.nan)\n",
    "\n",
    "df['age'] = int(datetime.now().strftime('%Y')) - df['year']\n",
    "df['average_rating'] = ((df['5 stars'] * 5) + (df['4 stars'] * 4) + (df['3 stars'] * 3) + (df['2 stars'] * 2) + df['1 star']) / df['num_ratings']\n",
    "df = df[['book_id', 'title', 'author', 'year', 'age', 'series', 'num_pages', 'genres', 'num_ratings', 'num_reviews', 'my_rating', 'average_rating', '5 stars', '4 stars', '3 stars', '2 stars', '1 star']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_quadratic(row):\n",
    "    x = np.array([1, 2, 3, 4, 5])\n",
    "    a, b, c = np.polyfit(x, row, 2)\n",
    "    return pd.Series([a, b, c])\n",
    "\n",
    "# Calculating quadrdic modeling coefficients\n",
    "df['1_star_percentage'] = df['1 star'] / df['num_ratings']\n",
    "df['2_star_percentage'] = df['2 stars'] / df['num_ratings']\n",
    "df['3_star_percentage'] = df['3 stars'] / df['num_ratings']\n",
    "df['4_star_percentage'] = df['4 stars'] / df['num_ratings']\n",
    "df['5_star_percentage'] = df['5 stars'] / df['num_ratings']\n",
    "coefficients = df[['1_star_percentage','2_star_percentage','3_star_percentage','4_star_percentage','5_star_percentage']].apply(fit_quadratic, axis=1)\n",
    "df['a'], df['b'], df['c'] = coefficients[0], coefficients[1], coefficients[2]\n",
    "\n",
    "# Pre-processing columns for rankings\n",
    "df['num_ratings_ln'] = np.log1p(df['num_ratings'])\n",
    "df['num_pages_ln'] = np.log1p(df['num_pages'])\n",
    "df['2a_shifted'] = df['a'] - df['a'].min()\n",
    "df['2a_shifted'] = df['2a_shifted'] * (1 / df['2a_shifted'].max()) + 1\n",
    "df['b_shifted'] = df['b'] - df['b'].min()\n",
    "df['b_shifted'] = df['b_shifted'] * (1 / df['b_shifted'].max()) + 1\n",
    "df['c_shifted'] = df['c'] - df['c'].min()\n",
    "df['c_shifted'] = df['c_shifted'] * (1 / df['c_shifted'].max()) + 1\n",
    "\n",
    "# Types of rankings\n",
    "df['num_adjusted_rating'] = df['average_rating'] - (df['average_rating'] - df['average_rating'].mean()) / df['num_ratings_ln']\n",
    "df['coeff_2a_rating'] = (df['num_adjusted_rating'] * df['2a_shifted'])\n",
    "df['coeff_b_rating'] = (df['num_adjusted_rating']) / (df['b_shifted'])\n",
    "df['coeff_c_rating'] = (df['num_adjusted_rating'] * df['c_shifted'])\n",
    "df['joined_rating'] = (df['num_adjusted_rating'] * df['c_shifted'] * df['2a_shifted']) / df['b_shifted']\n",
    "df['final_rating'] = df['joined_rating'] - (df['joined_rating'] - df['joined_rating'].mean()) / df['num_ratings_ln']\n",
    "\n",
    "df['num_adjusted_page_rating'] = df['num_adjusted_rating'] / (df['num_pages_ln'])\n",
    "df['coeff_2a_page_rating'] = df['coeff_2a_rating'] / df['num_pages_ln']\n",
    "df['coeff_b_page_rating'] = df['coeff_b_rating'] / df['num_pages_ln']\n",
    "df['coeff_c_page_rating'] = df['coeff_c_rating'] / df['num_pages_ln']\n",
    "df['joined_page_rating'] = df['joined_rating'] / df['num_pages_ln']\n",
    "df['final_page_rating'] = df['joined_page_rating'] - (df['joined_page_rating'] - df['joined_page_rating'].mean()) / df['num_ratings_ln']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = ['age', 'num_pages', 'num_pages_ln', 'num_ratings', 'num_ratings_ln', 'num_reviews', 'my_rating', 'average_rating', '1 star', '2 stars', '3 stars', '4 stars', '5 stars', '1_star_percentage', '2_star_percentage', '3_star_percentage', '4_star_percentage', '5_star_percentage', 'a', 'b', 'c', 'num_adjusted_rating', 'coeff_2a_rating', 'coeff_b_rating', 'coeff_c_rating', 'joined_rating', 'final_rating', 'num_adjusted_page_rating', 'coeff_2a_page_rating', 'coeff_b_page_rating', 'coeff_c_page_rating', 'joined_page_rating', 'final_page_rating']\n",
    "corr_df= df[numeric_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(20, 15)) \n",
    "sns.heatmap(corr_df, annot=True, cmap='coolwarm', linewidths=0.5) \n",
    "plt.title('Correlation Heatmap') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fresh = df.sort_values(by='final_page_rating', ascending=False).reset_index().drop('index', axis=1)\n",
    "fresh = fresh[fresh['my_rating'].isna()]\n",
    "fresh[['Fiction' in genre_list for genre_list in fresh['genres']]] # Fiction, Nonfiction, Memoir, Classics, History, Politics, Philosophy, Business"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
