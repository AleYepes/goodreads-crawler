{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "from requests import get\n",
    "import json\n",
    "import bs4\n",
    "import glob\n",
    "import ast\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mybooks(new_export_path):\n",
    "    # Remove previous \n",
    "    goodreads_export = f'data/goodreads_library_export.csv'\n",
    "    if os.path.isfile(goodreads_export):\n",
    "        os.remove(goodreads_export)\n",
    "\n",
    "    directory = '/Users/alex/Documents/testing/goodreads-ranker/data'\n",
    "    prefs = {'download.default_directory' : directory}\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_experimental_option('prefs', prefs)\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "    login_url = 'https://www.goodreads.com/ap/signin?language=en_US&openid.assoc_handle=amzn_goodreads_web_na&openid.claimed_id=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0%2Fidentifier_select&openid.identity=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0%2Fidentifier_select&openid.mode=checkid_setup&openid.ns=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0&openid.pape.max_auth_age=0&openid.return_to=https%3A%2F%2Fwww.goodreads.com%2Fap-handler%2Fsign-in'\n",
    "    driver.get(login_url)\n",
    "    WebDriverWait(driver, 60).until(EC.presence_of_element_located((By.CLASS_NAME, \"homePrimaryColumn\")))\n",
    "\n",
    "    driver.get('https://www.goodreads.com/review/import')\n",
    "    time.sleep(2)\n",
    "\n",
    "    current_date = datetime.now().strftime('%m/%d/%Y')\n",
    "    file_list = driver.find_element(By.CLASS_NAME, 'fileList')\n",
    "    if current_date not in file_list.text:\n",
    "        export_button = driver.find_element(By.CLASS_NAME, 'js-LibraryExport')\n",
    "        export_button.click()\n",
    "    WebDriverWait(driver, 60).until(EC.presence_of_element_located((By.CLASS_NAME, \"fileList\"))) # Maybe useless\n",
    "\n",
    "    while True:\n",
    "        file_list = driver.find_element(By.CLASS_NAME, 'fileList')\n",
    "        if current_date in file_list.text:\n",
    "            # find the link and click it\n",
    "            link = file_list.find_element(By.TAG_NAME, 'a')\n",
    "            link.click()\n",
    "            time.sleep(3)\n",
    "            break\n",
    "        else:\n",
    "            time.sleep(3)\n",
    "\n",
    "    os.rename('data/goodreads_library_export.csv', new_export_path)\n",
    "    goodreads_export = pd.read_csv(new_export_path)\n",
    "    driver.quit()\n",
    "    return goodreads_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_mybooks(new_export_path, this_months_scrape_path):\n",
    "    books_already_scraped = [int(file_name.replace(f'_metadata.json', '')) for file_name in os.listdir('metadata')]\n",
    "    try:\n",
    "        goodreads_export = pd.read_csv(new_export_path)\n",
    "    except FileNotFoundError:\n",
    "        goodreads_export = get_mybooks(new_export_path)\n",
    "    try:\n",
    "        recent_df = pd.read_csv(this_months_scrape_path)\n",
    "        recent_book_ids = recent_df['book_id'].tolist()\n",
    "        books_already_scraped = set(recent_book_ids + books_already_scraped)\n",
    "        print(books_already_scraped)\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "\n",
    "    book_ids = goodreads_export['Book Id'].tolist()\n",
    "    books_to_scrape = [id for id in book_ids if id not in books_already_scraped]\n",
    "\n",
    "    return book_ids, books_to_scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = set()\n",
    "test.remove('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# df = pd.read_csv('data/books.csv')\n",
    "# df = df[~df['similar_books'].isna()]\n",
    "# df['year'] = df['year'].astype(int)\n",
    "# df = df.drop(columns='Unnamed: 0')\n",
    "# df = df.drop_duplicates(subset=['id'])\n",
    "# df#.to_csv('data/goodreads_books_data.csv', index=False)\n",
    "\n",
    "df = pd.read_csv('data/goodreads_library_export.csv')\n",
    "df.columns = [col.lower().replace(' ','_') for col in df.columns]\n",
    "df#.to_csv('data/goodreads_library_export.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_books_tuples = [(1,2,3), (4,5,6)]\n",
    "\n",
    "\"|\".join(f\"{book_id}:{avg_rating}:{rating_count}\" for book_id, avg_rating, rating_count in similar_books_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_book(book_id):\n",
    "    def get_series_url(soup):\n",
    "        series_elem = soup.find('h3', {'class': 'Text Text__title3 Text__italic Text__regular Text__subdued'})\n",
    "        if series_elem:\n",
    "            series_slug = series_elem.find('a')['href'].split('/')[-1]\n",
    "            return series_slug\n",
    "        else:\n",
    "            print('    Series link not found')\n",
    "\n",
    "    def get_title(soup):\n",
    "        title_elem = soup.find('h1', {'class': 'Text Text__title1'})\n",
    "        if title_elem:\n",
    "            title = ' '.join(title_elem.text.split())\n",
    "            if title:\n",
    "                return title\n",
    "            else:\n",
    "                print('    Title not found')\n",
    "\n",
    "    def get_genres(soup):\n",
    "        genre_elems = soup.find_all('span', {'class': 'BookPageMetadataSection__genreButton'})\n",
    "        if genre_elems:\n",
    "            genres = []\n",
    "            for span in genre_elems:\n",
    "                genre = span.find('span', {'class': 'Button__labelItem'}).text\n",
    "                if genre != '...more':\n",
    "                    genres.append(genre)\n",
    "            return genres\n",
    "        else:\n",
    "            print('    Genres not found')\n",
    "\n",
    "    def get_script_data(soup):\n",
    "        try:\n",
    "            script_tag = soup.find('script', {'type': 'application/ld+json'})\n",
    "            data = json.loads(script_tag.string)\n",
    "            ratingCount = data.get('aggregateRating', {}).get('ratingCount', np.nan)\n",
    "            reviewCount = data.get('aggregateRating', {}).get('reviewCount', np.nan)\n",
    "            ratingValue = data.get('aggregateRating', {}).get('ratingValue', np.nan)\n",
    "        except AttributeError:\n",
    "            print(f\"    Script tag not found\")\n",
    "            ratingCount = np.nan\n",
    "            reviewCount = np.nan\n",
    "            ratingValue = np.nan\n",
    "\n",
    "        return {'num_ratings':          ratingCount,\n",
    "                'num_reviews':          reviewCount,\n",
    "                'average_rating':       ratingValue}\n",
    "\n",
    "    def get_rating_distribution(soup):\n",
    "        rating_bar_elems = soup.find_all('div', {'class': 'RatingsHistogram__bar'})\n",
    "        if rating_bar_elems:\n",
    "            distribution_dict = {}\n",
    "            for bar in rating_bar_elems:\n",
    "                star_label = bar['aria-label']\n",
    "                num_ratings = bar.find('div', {'class': 'RatingsHistogram__labelTotal'}).text.split(' ')[0]\n",
    "                num_ratings = int(num_ratings.replace(',', ''))\n",
    "                distribution_dict[star_label] = num_ratings\n",
    "            return distribution_dict\n",
    "        else:\n",
    "            print('    No rating bars found')\n",
    "\n",
    "    def get_num_pages(soup):\n",
    "        pages_elem = soup.find('p', {'data-testid': 'pagesFormat'})\n",
    "        if pages_elem:\n",
    "            try:\n",
    "                num_pages = int(pages_elem.text.split(' ')[0])\n",
    "            except Exception:\n",
    "                print('    No page number found')\n",
    "                num_pages = np.nan\n",
    "        else:\n",
    "            print('    No page number found')\n",
    "            num_pages = np.nan\n",
    "        return num_pages\n",
    "    \n",
    "    def get_author(soup):\n",
    "        author_elem = soup.find('span', {'class': 'ContributorLink__name'})\n",
    "        if author_elem:\n",
    "            author = author_elem.text.strip()\n",
    "        else:\n",
    "            print('    No author found')\n",
    "            author = np.nan\n",
    "        return author\n",
    "    \n",
    "    def get_year(soup):\n",
    "        year_elem = soup.find('p', {'data-testid': 'publicationInfo'})\n",
    "        if year_elem:\n",
    "            year = int(year_elem.text.split(', ')[-1])\n",
    "        else:\n",
    "            print('    Year not found')\n",
    "            year = np.nan\n",
    "        return year\n",
    "    \n",
    "    def get_type(soup):\n",
    "        pages_elem = soup.find('p', {'data-testid': 'pagesFormat'})\n",
    "        if pages_elem:\n",
    "            type = pages_elem.text.split(', ')[-1]\n",
    "        else:\n",
    "            print('    Type not found')\n",
    "            type = np.nan\n",
    "        return type\n",
    "    \n",
    "    url = f'https://www.goodreads.com/book/show/{book_id}'\n",
    "    source = get(url, timeout=30).text\n",
    "    soup = bs4.BeautifulSoup(source, 'html.parser')\n",
    "\n",
    "    return {**{'book_id': book_id,\n",
    "            'series': get_series_url(soup),\n",
    "            'title': get_title(soup),\n",
    "            'genres': get_genres(soup),\n",
    "            'author': get_author(soup),\n",
    "            'num_pages': get_num_pages(soup),\n",
    "            'year': get_year(soup),\n",
    "            'type': get_type(soup)},\n",
    "            **get_script_data(soup),\n",
    "            **get_rating_distribution(soup)}\n",
    "\n",
    "def condense_books(books_directory_path):\n",
    "    books = []\n",
    "    for file_name in os.listdir(books_directory_path):\n",
    "        if f'_metadata.json' in file_name:\n",
    "            book = json.load(open(f'metadata/{file_name}', 'r'))\n",
    "            books.append(book)\n",
    "    return books\n",
    "\n",
    "def delete_metadata():\n",
    "    directory = './metadata/*metadata.json'\n",
    "    files = glob.glob(directory)\n",
    "    for f in files:\n",
    "        os.remove(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main\n",
    "this_month = datetime.now().strftime('%m-%Y')\n",
    "this_day = datetime.now().strftime('%d-%m-%Y')\n",
    "new_export_path = f'data/{this_day}_goodreads_library_export.csv'\n",
    "this_months_scrape_path = f'data/{this_month}_goodreads_scraped.csv'\n",
    "\n",
    "while True:\n",
    "    book_ids, books_to_scrape = check_mybooks(new_export_path, this_months_scrape_path)\n",
    "    if books_to_scrape:\n",
    "        for i, book_id in enumerate(books_to_scrape):\n",
    "            try:\n",
    "                print(f'\\nScraping book-id:{book_id} ({i+1}/{len(books_to_scrape)})')\n",
    "                start = datetime.now()\n",
    "                book = scrape_book(book_id)\n",
    "                if book:\n",
    "                    json.dump(book, open(f'metadata/{book_id}_metadata.json', 'w'))\n",
    "                else:\n",
    "                    print(f'    scrape_book() returned empty')\n",
    "                print(f'{datetime.now() - start}')\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "\n",
    "        books = condense_books('metadata')\n",
    "        book_df = pd.DataFrame(books)\n",
    "        \n",
    "        if os.path.isfile(this_months_scrape_path):\n",
    "            old_df = pd.read_csv(this_months_scrape_path)\n",
    "            book_df = pd.concat([old_df, book_df])\n",
    "            book_df = book_df[book_df['book_id'].isin(book_ids)]\n",
    "            book_df = book_df.drop_duplicates(subset=[col for col in book_df.columns if col != 'genres'])\n",
    "\n",
    "        book_df.to_csv(this_months_scrape_path, index=False, encoding='utf-8')\n",
    "    else:\n",
    "        # delete_metadata()\n",
    "        print('ALL BOOKS HAVE BEEN SCRAPED')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodreads_export = pd.read_csv(new_export_path)\n",
    "# goodreads_export = pd.read_csv('data/20-01-2025_goodreads_library_export.csv')\n",
    "goodreads_export['Original Publication Year'] = goodreads_export['Original Publication Year'].fillna(goodreads_export['Year Published'])\n",
    "goodreads_export = goodreads_export[['Book Id', 'Author', 'My Rating', 'Number of Pages', 'Original Publication Year']]\n",
    "goodreads_export = goodreads_export.rename(columns={'Book Id':'book_id',\n",
    "                                                    'Author': 'author',\n",
    "                                                    'My Rating': 'my_rating',\n",
    "                                                    'Number of Pages': 'num_pages',\n",
    "                                                    'Original Publication Year': 'year'})\n",
    "threshold = (goodreads_export['num_pages'].mean() - goodreads_export['num_pages'].std())\n",
    "goodreads_export.loc[goodreads_export['num_pages'] < threshold, 'num_pages'] = np.nan\n",
    "\n",
    "book_df = pd.read_csv(this_months_scrape_path)\n",
    "# book_df = pd.read_csv('data/01-2025_goodreads_scraped.csv')\n",
    "df = goodreads_export.merge(book_df, on='book_id')\n",
    "\n",
    "# Drop competing columns\n",
    "df['author'] = df['author_x'].fillna(df['author_y'])\n",
    "df['num_pages'] = df['num_pages_x'].fillna(df['num_pages_y'])\n",
    "df['year'] = df['year_x'].fillna(df['year_y'])\n",
    "df.drop(columns=['author_x', 'author_y', 'num_pages_x', 'num_pages_y', 'year_x', 'year_y'], inplace=True)\n",
    "\n",
    "df['genres'] = df['genres'].apply(lambda x: ast.literal_eval(x) if pd.notna(x) else [])\n",
    "df['year'] = df['year'].fillna(df['year'].mean()).round().astype(int)\n",
    "df['num_pages'] = df['num_pages'].fillna(df['num_pages'].mean()).round().astype(int)\n",
    "df['num_reviews'] = df['num_reviews'].fillna(0).round().astype(int)\n",
    "df['my_rating'] = df['my_rating'].replace(0,np.nan)\n",
    "\n",
    "df['age'] = int(datetime.now().strftime('%Y')) - df['year']\n",
    "df['average_rating'] = ((df['5 stars'] * 5) + (df['4 stars'] * 4) + (df['3 stars'] * 3) + (df['2 stars'] * 2) + df['1 star']) / df['num_ratings']\n",
    "df = df[['book_id', 'title', 'author', 'year', 'age', 'series', 'num_pages', 'genres', 'num_ratings', 'num_reviews', 'my_rating', 'average_rating', '5 stars', '4 stars', '3 stars', '2 stars', '1 star']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_quadratic(row):\n",
    "    x = np.array([1, 2, 3, 4, 5])\n",
    "    a, b, c = np.polyfit(x, row, 2)\n",
    "    return pd.Series([a, b, c])\n",
    "\n",
    "# Calculating quadrdic modeling coefficients\n",
    "df['1_star_percentage'] = df['1 star'] / df['num_ratings']\n",
    "df['2_star_percentage'] = df['2 stars'] / df['num_ratings']\n",
    "df['3_star_percentage'] = df['3 stars'] / df['num_ratings']\n",
    "df['4_star_percentage'] = df['4 stars'] / df['num_ratings']\n",
    "df['5_star_percentage'] = df['5 stars'] / df['num_ratings']\n",
    "coefficients = df[['1_star_percentage','2_star_percentage','3_star_percentage','4_star_percentage','5_star_percentage']].apply(fit_quadratic, axis=1)\n",
    "df['a'], df['b'], df['c'] = coefficients[0], coefficients[1], coefficients[2]\n",
    "\n",
    "# Pre-processing columns for rankings\n",
    "df['num_ratings_ln'] = np.log1p(df['num_ratings'])\n",
    "df['num_pages_ln'] = np.log1p(df['num_pages'])\n",
    "df['2a_shifted'] = df['a'] - df['a'].min()\n",
    "df['2a_shifted'] = df['2a_shifted'] * (1 / df['2a_shifted'].max()) + 1\n",
    "df['b_shifted'] = df['b'] - df['b'].min()\n",
    "df['b_shifted'] = df['b_shifted'] * (1 / df['b_shifted'].max()) + 1\n",
    "df['c_shifted'] = df['c'] - df['c'].min()\n",
    "df['c_shifted'] = df['c_shifted'] * (1 / df['c_shifted'].max()) + 1\n",
    "\n",
    "# Types of rankings\n",
    "df['num_adjusted_rating'] = df['average_rating'] - (df['average_rating'] - df['average_rating'].mean()) / df['num_ratings_ln']\n",
    "df['coeff_2a_rating'] = (df['num_adjusted_rating'] * df['2a_shifted'])\n",
    "df['coeff_b_rating'] = (df['num_adjusted_rating']) / (df['b_shifted'])\n",
    "df['coeff_c_rating'] = (df['num_adjusted_rating'] * df['c_shifted'])\n",
    "df['joined_rating'] = (df['num_adjusted_rating'] * df['c_shifted'] * df['2a_shifted']) / df['b_shifted']\n",
    "df['final_rating'] = df['joined_rating'] - (df['joined_rating'] - df['joined_rating'].mean()) / df['num_ratings_ln']\n",
    "\n",
    "df['num_adjusted_page_rating'] = df['num_adjusted_rating'] / (df['num_pages_ln'])\n",
    "df['coeff_2a_page_rating'] = df['coeff_2a_rating'] / df['num_pages_ln']\n",
    "df['coeff_b_page_rating'] = df['coeff_b_rating'] / df['num_pages_ln']\n",
    "df['coeff_c_page_rating'] = df['coeff_c_rating'] / df['num_pages_ln']\n",
    "df['joined_page_rating'] = df['joined_rating'] / df['num_pages_ln']\n",
    "df['final_page_rating'] = df['joined_page_rating'] - (df['joined_page_rating'] - df['joined_page_rating'].mean()) / df['num_ratings_ln']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = ['age', 'num_pages', 'num_pages_ln', 'num_ratings', 'num_ratings_ln', 'num_reviews', 'my_rating', 'average_rating', '1 star', '2 stars', '3 stars', '4 stars', '5 stars', '1_star_percentage', '2_star_percentage', '3_star_percentage', '4_star_percentage', '5_star_percentage', 'a', 'b', 'c', 'num_adjusted_rating', 'coeff_2a_rating', 'coeff_b_rating', 'coeff_c_rating', 'joined_rating', 'final_rating', 'num_adjusted_page_rating', 'coeff_2a_page_rating', 'coeff_b_page_rating', 'coeff_c_page_rating', 'joined_page_rating', 'final_page_rating']\n",
    "corr_df= df[numeric_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(20, 15)) \n",
    "sns.heatmap(corr_df, annot=True, cmap='coolwarm', linewidths=0.5) \n",
    "plt.title('Correlation Heatmap') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fresh = df.sort_values(by='final_page_rating', ascending=False).reset_index().drop('index', axis=1)\n",
    "fresh = fresh[fresh['my_rating'].isna()]\n",
    "fresh[['Fiction' in genre_list for genre_list in fresh['genres']]] # Fiction, Nonfiction, Memoir, Classics, History, Politics, Philosophy, Business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('books_data.csv')\n",
    "test#['author'].iloc[]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
